<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="Predicting and Visualizing Flight Delays : Final Project for Computer Science 109: Data Science" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Predicting and Visualizing Flight Delays</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/nyassin/CS109_Visualization">View on GitHub</a>

          <h1 id="project_title">Predicting and Visualizing Flight Delays</h1>
          <h2 id="project_tagline">Final Project for Computer Science 109: Data Science</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/nyassin/CS109_Visualization/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/nyassin/CS109_Visualization/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h2>
<a name="process-book" class="anchor" href="#process-book"><span class="octicon octicon-link"></span></a>Process Book</h2>

<p>Hello and welcome to our CS109 Process book!</p>

<p>The goal of our project was to explore the world of flight delays and look at how weather factors in. Our original intention was to predict delays based upon weather at the origin airport. We gathered the flight data and matched it to scraped weather data at the origin airport. We then produced both significant visualizations of the the interplay of weather and flight delays and experimented with multiple regression and classification models.  The conclusion was that it is very difficult to predict flight delays. Airports now handle medium to bad weather well and a significant number of delays are due to chance or hard to follow network effects.
We hope you enjoy browsing our project.</p>

<p>Ian Boothby, Daniel Broudy, Jamie Law-Smith, Nuseir Yassin. </p>

<h2>
<a name="weather-scraping" class="anchor" href="#weather-scraping"><span class="octicon octicon-link"></span></a>Weather Scraping</h2>

<p>We obtained data from the National Oceanic and Atmospheric Administration, an arm of the National Climatic Data Center, which releases extremely detailed weather datasets for weather stations around the country. These were obtained from a combination of the ISD-Lite dataset, which includes hourly data, and the GSOD dataset, which includes daily statistics.
Due to the quirky format that the NOAA uses for its data files, the process of collecting that data took extensive work and is well documented in our linked process book. </p>

<p><a href="http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/weather_scraping.ipynb?create=1">Weather Scraping code</a></p>

<h2>
<a name="flight-scraping" class="anchor" href="#flight-scraping"><span class="octicon octicon-link"></span></a>Flight Scraping</h2>

<p>We obtained flight data from the Bureau of Transportation Statistics’ (BTS) <a href="http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&amp;DB_Short_Name=On-Time">On-Time Performance</a> dataset, which has extremely detailed information about the delays, causes of delay, route characteristics, etc. of every flight in every airport in the US. 
For our purposes, this was an overwhelming amount of data, so we chose to focus on the top 20 busiest airports in the US. Given the spoke-and-hub strategy of most airlines, in which flights are routed through connecting hubs, these 20 airports represent a majority of the traffic in the US already, and are presumably also centers of delays, since one delay at a hub can spill over to all connecting flights.
A complete list of the fields that we chose to download is listed at the bottom of the ipython notebook--these included causes of delay classified by the BTS <a href="http://www.rita.dot.gov/bts/help/aviation/html/understanding.html">here</a>, airtime, day of the week, etc.</p>

<p><a href="http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/flight_scraping.ipynb?create=1">Flight scraping code</a></p>

<h2>
<a name="matching-flights-with-weather-data" class="anchor" href="#matching-flights-with-weather-data"><span class="octicon octicon-link"></span></a>Matching Flights with Weather Data</h2>

<p>We’ve now aggregated 3.5 million flights for the year 2012 alone. However, both datasets were separate and combining the two locally to match each hour of weather to the corresponding flight departure times would take a sizable amount of time (17 hours in our estimation). We wrote a MapReduce job to scale our computation to Amazon EC2 instances. MrJob Input. </p>

<p>After running 15 EC2 instances for approximately 20 minutes, we got a fully concatenated dataset, and with a little more cleaning, we arrived at our full dataset (maindata/fulldf.csv). Due to the unwieldly size of the dataset for analysis, we created a random subset 1/100th of the size (maindata/smalldf.csv).</p>

<p><a href="http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/dfcombiner_mrjob.py?create=1">MapReduce Code</a></p>

<h2>
<a name="sizing-up-the-data" class="anchor" href="#sizing-up-the-data"><span class="octicon octicon-link"></span></a>Sizing Up The Data</h2>

<p>This is an example of an early notebook in which we opened and explored the flight and weather data for the first time. It was in this notebook that we decided to limit our discussion to only departures from the top 20 busiest airports in the United States. We also determined that we wanted to limit our discussion to weather-related delays in order to get a more predictable subset of flight delays. We followed the FAA threshold of 15 minutes before declaring a flight delayed and decided to count canceled flights as delayed. In this notebook we plotted weather patterns of canceled flights and determined that they were on average due to more extreme weather which fit well with the weather related delays we intended to predict. </p>

<p><a href="http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/Sizing%20up%20the%20data.ipynb?create=1">Sizing up the data notebook</a></p>

<h2>
<a name="visualizations" class="anchor" href="#visualizations"><span class="octicon octicon-link"></span></a>Visualizations</h2>

<p>To develop a better understanding of our scraped and combined data, we created two D3 visualizations. The first visualization is based on the CrossFilter library provided by Square. <a href="http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/master/Flight_Visualization.ipynb?create=1">Flight Visualization - Data Collection</a></p>

<p>First, we re-created a special comma separated dataset  that has all the necessary information we need for the visualization (like Weather, Pressure, delay, etc). Flight Visualization - Data Collection. Then we tweaked the CrossFilter model and added our own filters. Most importantly, we generated an interactive pie chart, which we think is a better visualization than a simple bar chart.
<a href="http://bl.ocks.org/nyassin/raw/7938499/">Flight Visualization Using CrossFilter</a></p>

<p>We also wanted to take advantage of D3’s geoPath abilities. We plotted the 20 top airports on a US map and connected them with flight paths that resembled either flights or delays depending on the user toggle.<a href="http://bl.ocks.org/nyassin/raw/7938379/">Flight Visualization Using Maps</a></p>

<p>Visualizations closely mirror our statistical analysis. Our findings are documented in their respective visualization files. </p>

<h2>
<a name="linear-regression" class="anchor" href="#linear-regression"><span class="octicon octicon-link"></span></a>Linear Regression</h2>

<p>Our initial explorations also involved trying to find simple correlations between predictors and minutes of delay time, trying to get a sense of which factors were most important in predicting delay. Unfortunately, these were largely unsuccessful, in particular because extreme values of weather and other predictors led to a mix of delayed and on-time flights. The large volume of flights that are slightly delayed was problematic. These short delays could simply be the result of noise from minor efficiencies like slow boarding/cleaning/refueling, but they played a big role in making prediction difficult.
This revealed to us one of the fundamental problems of trying to predict delays: most delays, particularly shorter delays, are the result of rather unpredictable, noisy factors. For instance, specific mechanical failures are hard to predict : if they were frequent for certain aircraft, these planes probably would have been taken off the market. Our most detailed features concerned weather, but many delays are not weather-related.
Indeed, weather delays accounted for only a small portion of delays, the largest cause being late incoming aircraft (which is a product of delays at the previous airport from which the aircraft was arriving).  Although these types of failures could be predicted in aggregate, predicting them for any single flight is a difficult task, particularly given the interconnected nature of the national flight network.</p>

<p><a href="http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/Linear%20Regression%20and%20Exploration.ipynb?create=1">Linear Regression Code</a></p>

<h2>
<a name="logistic-regression" class="anchor" href="#logistic-regression"><span class="octicon octicon-link"></span></a>Logistic Regression</h2>

<p>Based on our experience in exploration, we decided to model delays as a binary outcome (delayed or not delayed) to eliminate noise from minor delays. We started by trying to run and optimize a logistic regression model, with somewhat limited success. Accuracy was high, but only because most flights are not delayed; simply predicting that every flight would be on-time is a relatively accurate method too. Our model struggled in particular to classify flights that were actually delayed; it tended to predict too few delays overall.
This is likely due in part to the massive number of categorical predictors we have. While dummy variables can be effective in limited use, they are not particularly informative since they can only assume one of two values. It might have been better to do separate regressions for each airline/airport combination, but this would lose the predictive value that each airline and airport contributes to prediction.
In an attempt to more accurately sample from the parameter space, we also constructed a markov chain monte carlo (MCMC) based on the Metropolis-Hastings algorithms to estimate the parameters of the logistic regression. Unfortunately, we didn’t have much time to debug and optimize this code, and when running test data that should have fit quite well, our chain failed to converge in a reasonable number of attempts.</p>

<p><a href="http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/LogR_dev.ipynb?create=1">Logistic Regression Code</a></p>

<h2>
<a name="multivariate-regression" class="anchor" href="#multivariate-regression"><span class="octicon octicon-link"></span></a>Multivariate Regression</h2>

<p><a href="http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/Multilevel%20Regression.ipynb?create=1">Multivariate Regression</a></p>

<h2>
<a name="randomforest" class="anchor" href="#randomforest"><span class="octicon octicon-link"></span></a>RandomForest</h2>

<p>This was our most successful classifier. We selected Random Forests in an effort to explore a methodology that was not covered in the problem sets of the course. In our efforts we found <a href="http://blog.yhathq.com/posts/random-forests-in-python.html">this blog</a> very helpful. We went through many iterations of feature lists and discovered new inputs that we decided to go back and scrape to add to our flight dataset. It is misleading to look at the score in predicting flight delays because delays are rare events. We used the metrics of precision and recall to examine our ability to distinguish the delayed flights from normal flights. 
We had limited success in calibrating the model and producing a successful classifier. This is documented in our ipython notebook linked above.</p>

<p><a href="http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/RandomForest.ipynb?create=1">Random Forest Book</a></p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Predicting and Visualizing Flight Delays maintained by <a href="https://github.com/nyassin">nyassin</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
