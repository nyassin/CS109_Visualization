{"name":"Predicting and Visualizing Flight Delays","tagline":"Final Project for Computer Science 109: Data Science","body":"##Process Book \r\n\r\nHello and welcome to our CS109 Process book!\r\n\r\nThe goal of our project was to explore the world of flight delays and look at how weather factors in. Our original intention was to predict delays based upon weather at the origin airport. We gathered the flight data and matched it to scraped weather data at the origin airport. We then produced both significant visualizations of the the interplay of weather and flight delays and experimented with multiple regression and classification models.  The conclusion was that it is very difficult to predict flight delays. Airports now handle medium to bad weather well and a significant number of delays are due to chance or hard to follow network effects.\r\nWe hope you enjoy browsing our project.\r\n\r\nIan Boothby, Daniel Broudy, Jamie Law-Smith, Nuseir Yassin. \r\n\r\n\r\n## Weather Scraping\r\n\r\nWe obtained data from the National Oceanic and Atmospheric Administration, an arm of the National Climatic Data Center, which releases extremely detailed weather datasets for weather stations around the country. These were obtained from a combination of the ISD-Lite dataset, which includes hourly data, and the GSOD dataset, which includes daily statistics.\r\nDue to the quirky format that the NOAA uses for its data files, the process of collecting that data took extensive work and is well documented in our linked process book. \r\n\r\n[Weather Scraping code]( http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/weather_scraping.ipynb?create=1)\r\n\r\n## Flight Scraping\r\nWe obtained flight data from the Bureau of Transportation Statistics’ (BTS) [On-Time Performance](http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time) dataset, which has extremely detailed information about the delays, causes of delay, route characteristics, etc. of every flight in every airport in the US. \r\nFor our purposes, this was an overwhelming amount of data, so we chose to focus on the top 20 busiest airports in the US. Given the spoke-and-hub strategy of most airlines, in which flights are routed through connecting hubs, these 20 airports represent a majority of the traffic in the US already, and are presumably also centers of delays, since one delay at a hub can spill over to all connecting flights.\r\nA complete list of the fields that we chose to download is listed at the bottom of the ipython notebook--these included causes of delay classified by the BTS [here](http://www.rita.dot.gov/bts/help/aviation/html/understanding.html), airtime, day of the week, etc.\r\n\r\n[Flight scraping code](http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/flight_scraping.ipynb?create=1)\r\n\r\n## Matching Flights with Weather Data\r\nWe’ve now aggregated 3.5 million flights for the year 2012 alone. However, both datasets were separate and combining the two locally to match each hour of weather to the corresponding flight departure times would take a sizable amount of time (17 hours in our estimation). We wrote a MapReduce job to scale our computation to Amazon EC2 instances. \r\n\r\nAfter running 15 EC2 instances for approximately 20 minutes, we got a fully concatenated dataset, and with a little more cleaning, we arrived at our full dataset (maindata/fulldf.csv). Due to the unwieldly size of the dataset for analysis, we created a random subset 1/100th of the size (maindata/smalldf.csv).\r\n\r\n[MapReduce Code](http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/dfcombiner_mrjob.py?create=1)\r\n\r\n## Sizing Up The Data\r\n\r\nThis is an example of an early notebook in which we opened and explored the flight and weather data for the first time. It was in this notebook that we decided to limit our discussion to only departures from the top 20 busiest airports in the United States. We also determined that we wanted to limit our discussion to weather-related delays in order to get a more predictable subset of flight delays. We followed the FAA threshold of 15 minutes before declaring a flight delayed and decided to count canceled flights as delayed. In this notebook we plotted weather patterns of canceled flights and determined that they were on average due to more extreme weather which fit well with the weather related delays we intended to predict. \r\n\r\n[Sizing up the data notebook](http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/Sizing%20up%20the%20data.ipynb?create=1)\r\n\r\n## Visualizations \r\n\r\nTo develop a better understanding of our scraped and combined data, we created two D3 visualizations. The first visualization is based on the CrossFilter library provided by Square. [Flight Visualization - Data Collection](http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/master/Flight_Visualization.ipynb?create=1)\r\n\r\nFirst, we re-created a special comma separated dataset  that has all the necessary information we need for the visualization (like Weather, Pressure, delay, etc). Flight Visualization - Data Collection. Then we tweaked the CrossFilter model and added our own filters. Most importantly, we generated an interactive pie chart, which we think is a better visualization than a simple bar chart.\r\n[Flight Visualization Using CrossFilter](http://bl.ocks.org/nyassin/raw/7938499/)\r\n\r\n\r\nWe also wanted to take advantage of D3’s geoPath abilities. We plotted the 20 top airports on a US map and connected them with flight paths that resembled either flights or delays depending on the user toggle.[Flight Visualization Using Maps](http://bl.ocks.org/nyassin/raw/7938379/)\r\n\r\nVisualizations closely mirror our statistical analysis. Our findings are documented in their respective visualization files. \r\n\r\n\r\n## Linear Regression \r\n\r\nOur initial explorations also involved trying to find simple correlations between predictors and minutes of delay time, trying to get a sense of which factors were most important in predicting delay. Unfortunately, these were largely unsuccessful, in particular because extreme values of weather and other predictors led to a mix of delayed and on-time flights. The large volume of flights that are slightly delayed was problematic. These short delays could simply be the result of noise from minor efficiencies like slow boarding/cleaning/refueling, but they played a big role in making prediction difficult.\r\nThis revealed to us one of the fundamental problems of trying to predict delays: most delays, particularly shorter delays, are the result of rather unpredictable, noisy factors. For instance, specific mechanical failures are hard to predict : if they were frequent for certain aircraft, these planes probably would have been taken off the market. Our most detailed features concerned weather, but many delays are not weather-related.\r\nIndeed, weather delays accounted for only a small portion of delays, the largest cause being late incoming aircraft (which is a product of delays at the previous airport from which the aircraft was arriving).  Although these types of failures could be predicted in aggregate, predicting them for any single flight is a difficult task, particularly given the interconnected nature of the national flight network.\r\n\r\n[Linear Regression Code](http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/Linear%20Regression%20and%20Exploration.ipynb?create=1)\r\n\r\n\r\n## Logistic Regression\r\n\r\nBased on our experience in exploration, we decided to model delays as a binary outcome (delayed or not delayed) to eliminate noise from minor delays. We started by trying to run and optimize a logistic regression model, with somewhat limited success. Accuracy was high, but only because most flights are not delayed; simply predicting that every flight would be on-time is a relatively accurate method too. Our model struggled in particular to classify flights that were actually delayed; it tended to predict too few delays overall.\r\nThis is likely due in part to the massive number of categorical predictors we have. While dummy variables can be effective in limited use, they are not particularly informative since they can only assume one of two values. It might have been better to do separate regressions for each airline/airport combination, but this would lose the predictive value that each airline and airport contributes to prediction.\r\nIn an attempt to more accurately sample from the parameter space, we also constructed a markov chain monte carlo (MCMC) based on the Metropolis-Hastings algorithms to estimate the parameters of the logistic regression. Unfortunately, we didn’t have much time to debug and optimize this code, and when running test data that should have fit quite well, our chain failed to converge in a reasonable number of attempts.\r\n\r\n[Logistic Regression Code](http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/LogR_dev.ipynb?create=1)\r\n## Multivariate Regression \r\n\r\n[Multivariate Regression](http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/Multilevel%20Regression.ipynb?create=1)\r\n\r\n\r\n## SVM Methods\r\n\r\nWe explored Support Vector Machines as another potential classifier in predicting delays. We found that SVM methods predicted far too few delays (on the order of 5 to 10) to be useful. We also tried the related Support Vector Regression in order to get predicted percentage chance of delays. Less than 1% of the predictions were above 0.5 of a flight being delayed, and since our goal in this project was to predict the binary delayed/not delayed, SVRs did not seem a useful avenue. Initial forays in RandomForests were more fruitful, and so we abandoned SVM methods in favor of RFs.\r\n \r\n[SVM Methods code](http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/SVM.ipynb?create=1)\r\n## RandomForest \r\n\r\nThis was our most successful classifier. We selected Random Forests in an effort to explore a methodology that was not covered in the problem sets of the course. In our efforts we found [this blog](http://blog.yhathq.com/posts/random-forests-in-python.html) very helpful. We went through many iterations of feature lists and discovered new inputs that we decided to go back and scrape to add to our flight dataset. It is misleading to look at the score in predicting flight delays because delays are rare events. We used the metrics of precision and recall to examine our ability to distinguish the delayed flights from normal flights. \r\nWe had limited success in calibrating the model and producing a successful classifier. This is documented in our ipython notebook linked above.\r\n\r\n[Random Forest Book](http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/RandomForest.ipynb?create=1)\r\n\r\n\r\n## Summary\r\n\r\nIn summary this project was much more ambitious than we realized at the time of our project proposal. Flight delays are not as influenced by weather as we expected and most other delays are caused by rare events like mechanical failure or network-dependent events like late aircraft delay. We have now wrestled with and realized just how hard it is to work with a real world problem. Scraping and cleaning the data took a significant amount of time. \r\n\r\nPart of our rationale for trying several different models was because, unlike on problem sets, the initial models we tried were quite poor. In retrospect we wish that we pursued an individual method in more depth and in a more rigorous manner with respect to calibration and assessment. Our predictor never became accurate enough to make it worth while to set up a way of testing it on real flights in 2013. In the end we had a lot of fun learning about scraping, working with a real world problem and letting our imagination takeoff ;) .\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}