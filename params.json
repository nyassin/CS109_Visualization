{"name":"Predicting and Visualizing Flight Delays","tagline":"Final Project for Computer Science 109: Data Science","body":"Hello and welcome to our CS109 Process book!\r\n\r\nThe goal of our project was to explore the world of flight delays and look at how weather factors in. Our original intention was to predict delays based upon weather at the origin airport. We gathered the flight data and matched it to scraped weather data at the origin airport. We then produced both significant visualizations of the the interplay of weather and flight delays and experimented with multiple regression and classification models.  The conclusion was that it is very difficult to predict flight delays. Airports now handle medium to bad weather well and a significant number of delays are due to chance or hard to follow network effects.\r\nWe hope you enjoy browsing our project.\r\n\r\nIan Boothby, Daniel Broudy, Jamie Law-Smith, Nuseir Yassin. \r\n\r\n\r\n## Weather Scraping\r\n\r\nWe obtained data from the National Oceanic and Atmospheric Administration, an arm of the National Climatic Data Center, which releases extremely detailed weather datasets for weather stations around the country. These were obtained from a combination of the ISD-Lite dataset, which includes hourly data, and the GSOD dataset, which includes daily statistics.\r\nDue to the quirky format that the NOAA uses for its data files, the process of collecting that data took extensive work and is well documented in our linked process book. \r\n\r\n[Weather Scraping code]( http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/weather_scraping.ipynb?create=1)\r\n\r\n## Flight Scraping\r\nWe obtained flight data from the Bureau of Transportation Statistics’ (BTS) [On-Time Performance](http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time) dataset, which has extremely detailed information about the delays, causes of delay, route characteristics, etc. of every flight in every airport in the US. \r\nFor our purposes, this was an overwhelming amount of data, so we chose to focus on the top 20 busiest airports in the US. Given the spoke-and-hub strategy of most airlines, in which flights are routed through connecting hubs, these 20 airports represent a majority of the traffic in the US already, and are presumably also centers of delays, since one delay at a hub can spill over to all connecting flights.\r\nA complete list of the fields that we chose to download is listed at the bottom of the ipython notebook--these included causes of delay classified by the BTS here, airtime, day of the week, etc.\r\n\r\n[Flight scraping code](http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/flight_scraping.ipynb?create=1)\r\n\r\n## Matching Flights with Weather Data\r\nWe’ve now aggregated 3.5 million flights for the year 2012 alone. However, both datasets were separate and combining the two locally to match each hour of weather to the corresponding flight departure times would take a sizable amount of time (17 hours in our estimation). We wrote a MapReduce job to scale our computation to Amazon EC2 instances. MrJob Input. \r\n\r\nAfter running 15 EC2 instances for approximately 20 minutes, we got a fully concatenated dataset, and with a little more cleaning, we arrived at our full dataset (maindata/fulldf.csv). Due to the unwieldly size of the dataset for analysis, we created a random subset 1/100th of the size (maindata/smalldf.csv).\r\n\r\n[MapReduce Code](http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/dfcombiner_mrjob.py?create=1)\r\n\r\n## Sizing Up The Data\r\n\r\nWAITING ON IT\r\n\r\n## Visualizations \r\n\r\nTo develop a better understanding of our scraped and combined data, we created two D3 visualizations. The first visualization is based on the CrossFilter library provided by Square. [Flight Visualization - Data Collection](http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/master/Flight_Visualization.ipynb?create=1)\r\n\r\nFirst, we re-created a special comma separated dataset  that has all the necessary information we need for the visualization (like Weather, Pressure, delay, etc). Flight Visualization - Data Collection. Then we tweaked the CrossFilter model and added our own filters. Most importantly, we generated an interactive pie chart, which we think is a better visualization than a simple bar chart.\r\n[Flight Visualization Using CrossFilter](http://bl.ocks.org/nyassin/raw/7938499/)\r\n\r\n\r\nWe also wanted to take advantage of D3’s geoPath abilities. We plotted the 20 top airports on a US map and connected them with flight paths that resembled either flights or delays depending on the user toggle.[Flight Visualization Using Maps](http://bl.ocks.org/nyassin/raw/7938379/)\r\n\r\nVisualizations closely mirror our statistical analysis. Our findings are documented in their respective visualization files. \r\n\r\n\r\n## Linear Regression \r\n\r\n[Linear Regression ]( http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/Linear%20Regression%20and%20Exploration.ipynb?create=1  )\r\n## Logistical Regression\r\n\r\n[Logistic Regression](hhttp://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/LogR_dev.ipynb?create=1)\r\n\r\n## Multivariate Regression \r\n\r\n[Multivariate Regression](http://nbviewer.ipython.org/github/nyassin/CS109_Visualization/blob/gh-pages/modeling/Multilevel%20Regression.ipynb?create=1)\r\n\r\n## RandomForest ","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}